{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autorzy\n",
    "- Mateusz Łopaciński\n",
    "- Mateusz Mazur"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "data = loadmat('./data/leukemia.mat')\n",
    "X = data['X']\n",
    "y = data['Y'].ravel()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usuwanie cech charakteryzujących się niską wariancją"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import potrzebnych bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usuwanie cech o niskiej wariancji"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dzielimy oryginalny zbór na zbiór treningowy i testowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wybieramy próg, dla którego obserwujemy zmianę skuteczności predykcji (metodą prób i błędów, obserwując zmiany wartości `accuracy`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usuwamy z wyjściowego zbioru cechy o niskiej wariancji i dzielimy powstały zbiór na zbiór treningowy i testowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = VarianceThreshold(threshold)\n",
    "X_transformed = selector.fit_transform(X)\n",
    "\n",
    "X_train_high_variance, X_test_high_variance, y_train, y_test = train_test_split(X_transformed, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trenowanie klasyfikatora `Random Forest` dla obu zbiorów"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trenujemy klasyfikator Random Forest i wyznaczamy `accuracy` dla oryginalnego zbioru oraz zbioru bez cech o niskiej wariancji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original dataset\n",
    "clf_original = RandomForestClassifier(random_state=42)\n",
    "clf_original.fit(X_train, y_train.ravel())\n",
    "y_pred_original = clf_original.predict(X_test)\n",
    "accuracy_original = accuracy_score(y_test, y_pred_original)\n",
    "\n",
    "# Dataset after removing low variance features\n",
    "clf_high_variance = RandomForestClassifier(random_state=42)\n",
    "clf_high_variance.fit(X_train_high_variance, y_train.ravel())\n",
    "y_pred_high_variance = clf_high_variance.predict(X_test_high_variance)\n",
    "accuracy_high_variance = accuracy_score(y_test, y_pred_high_variance)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Porównanie skuteczności predykcji"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porównujemy otrzymane wyniki. Jak widać, usunięcie cech o niskiej wariancji, powoduje spadek skuteczności predykcji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skuteczność na oryginalnym zbiorze: 100.00\n",
      "Skuteczność po usunięciu cech o niskiej wariancji: 95.45\n"
     ]
    }
   ],
   "source": [
    "print(\"Skuteczność na oryginalnym zbiorze: {:.2f}\".format(accuracy_original * 100))\n",
    "print(\"Skuteczność po usunięciu cech o niskiej wariancji: {:.2f}\".format(accuracy_high_variance * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wybór `m` najlepszych cech"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import potrzebnych bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wybór liczby cech ze zbioru treningowego"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wybieramy liczbę `m` cech, które będziemy chcieli wyznaczyć, przy pomocy algorytmu `RFE`. Stosujemy się do sugestii, że docelowa liczba cech nie powinna przekraczać $1/3$ cech ze zbioru treningowego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_instances = X_train_high_variance.shape[0]\n",
    "m = n_instances // 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trening klasyfikatorów"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korzystamy z klasyfikatora regresji logistycznej do wyznaczenia `m` najlepszych cech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_lr = LogisticRegression()\n",
    "rfe_lr = RFE(estimator=estimator_lr, n_features_to_select=m)\n",
    "X_train_selected_lr = rfe_lr.fit_transform(X_train_high_variance, y_train.ravel())\n",
    "X_test_selected_lr = rfe_lr.transform(X_test_high_variance)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W tym samym celu, wykorzystujemy klasyfikator lasów losowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_rf = RandomForestClassifier(random_state=42)\n",
    "rfe_rf = RFE(estimator=estimator_rf, n_features_to_select=m)\n",
    "X_train_selected_rf = rfe_rf.fit_transform(X_train_high_variance, y_train.ravel())\n",
    "X_test_selected_rf = rfe_rf.transform(X_test_high_variance)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wpływ metryk na dokładność klasyfikacji"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import potrzebnych bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Badanie wpływy metryk na dokładność klasyfikacji"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korzystamy z 4-krotnej walidacji krzyżowej oraz obu wytrenowanych wcześniej klasyfikatorów. Wyznaczamy dokładność, przy pomocy metryki `AUC` oraz metryki `accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 4\n",
    "\n",
    "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "mean_accuracy_lr = np.mean(cross_val_score(rfe_lr, X_transformed, y.ravel(), cv=cv, scoring='accuracy'))\n",
    "mean_accuracy_rf = np.mean(cross_val_score(rfe_rf, X_transformed, y.ravel(), cv=cv, scoring='accuracy'))\n",
    "\n",
    "mean_auc_lr = np.mean(cross_val_score(rfe_lr, X_transformed, y.ravel(), cv=cv, scoring='roc_auc'))\n",
    "mean_auc_rf = np.mean(cross_val_score(rfe_rf, X_transformed, y.ravel(), cv=cv, scoring='roc_auc'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Porównanie wyników"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widzimy, korzystając z metryki `AUC`, otrzymujemy dużo wyższe wyniki w przypadku obu klasyfikatorów niż dla metryki dokładności (`accuracy`). W przypadku lasów losowych oraz regresji logistycznej otrzymaliśmy takie same wyniki dla obu klasyfikatorów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Średnia dokładność dla regresji logistycznej: 93.06\n",
      "Średnia dokładność dla lasów losowych: 93.06\n",
      "Średnia metryka AUC dla regresji logistycznej: 98.29\n",
      "Średnia metryka AUC dla lasów losowych: 99.31\n"
     ]
    }
   ],
   "source": [
    "print(\"Średnia dokładność dla regresji logistycznej: {:.2f}\".format(mean_accuracy_lr * 100))\n",
    "print(\"Średnia dokładność dla lasów losowych: {:.2f}\".format(mean_accuracy_rf * 100))\n",
    "\n",
    "print(\"Średnia metryka AUC dla regresji logistycznej: {:.2f}\".format(mean_auc_lr * 100))\n",
    "print(\"Średnia metryka AUC dla lasów losowych: {:.2f}\".format(mean_auc_rf * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Porównanie dokładności wbudowanymi metodami selekcji cech"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import potrzebnych bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selekcja cech wbudowanymi metodami"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trening klasyfikatorów"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresja logistyczna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_lr = LogisticRegression(solver='saga', penalty='l1', C=0.1, max_iter=1000)\n",
    "mean_accuracy_lr_l1 = np.mean(cross_val_score(estimator_lr, X_transformed, y.ravel(), cv=cv, scoring='accuracy'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasy losowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_rf = RandomForestClassifier(random_state=42)\n",
    "selector_rf = SelectFromModel(estimator_rf)\n",
    "X_transformed_rf = selector_rf.fit_transform(X_transformed, y.ravel())\n",
    "mean_accuracy_rf_se = np.mean(cross_val_score(estimator_rf, X_transformed_rf, y.ravel(), cv=cv, scoring='accuracy'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Porównanie wyników"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność regresji logistycznej: 93.06\n",
      "Dokładność lasów losowych: 93.06\n",
      "Dokładność regresji logistycznej z regularyzacją L1: 88.89\n",
      "Dokładność lasów losowych z metodą ważności cech: 93.06\n"
     ]
    }
   ],
   "source": [
    "print(\"Dokładność regresji logistycznej: {:.2f}\".format(mean_accuracy_lr * 100))\n",
    "print(\"Dokładność lasów losowych: {:.2f}\".format(mean_accuracy_rf * 100))\n",
    "print(\"Dokładność regresji logistycznej z regularyzacją L1: {:.2f}\".format(mean_accuracy_lr_l1 * 100))\n",
    "print(\"Dokładność lasów losowych z metodą ważności cech: {:.2f}\".format(mean_accuracy_rf_se * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PSI",
   "language": "python",
   "name": "psi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
