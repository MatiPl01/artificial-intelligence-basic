{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autorzy\n",
    "- Mateusz Łopaciński\n",
    "- Mateusz Mazur"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "data = loadmat('./data/leukemia.mat')\n",
    "X = data['X']\n",
    "y = data['Y'].ravel()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usuwanie cech charakteryzujących się niską wariancją"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importujemy potrzebne biblioteki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dzielimy zbiór na treningowy i testowy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przyjmujemy próg dla wariancji, poniżej którego cechy będą usuwane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obliczamy wariancję i do dalszych predykcji używamy tylko te cechy, spełniające warunek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = VarianceThreshold(threshold)\n",
    "X_transformed = selector.fit_transform(X)\n",
    "\n",
    "X_train_high_variance, X_test_high_variance, y_train, y_test = train_test_split(X_transformed, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 14)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porównanie skuteczności przed i po zmianach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original dataset\n",
    "clf_original = RandomForestClassifier(random_state=42)\n",
    "clf_original.fit(X_train, y_train.ravel())\n",
    "y_pred_original = clf_original.predict(X_test)\n",
    "accuracy_original = accuracy_score(y_test, y_pred_original)\n",
    "\n",
    "# Dataset after removing low variance features\n",
    "clf_high_variance = RandomForestClassifier(random_state=42)\n",
    "clf_high_variance.fit(X_train_high_variance, y_train.ravel())\n",
    "y_pred_high_variance = clf_high_variance.predict(X_test_high_variance)\n",
    "accuracy_high_variance = accuracy_score(y_test, y_pred_high_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skuteczność na oryginalnym zbiorze: 100.00\n",
      "Skuteczność po usunięciu cech o niskiej wariancji: 95.45\n"
     ]
    }
   ],
   "source": [
    "print(\"Skuteczność na oryginalnym zbiorze: {:.2f}\".format(accuracy_original * 100))\n",
    "print(\"Skuteczność po usunięciu cech o niskiej wariancji: {:.2f}\".format(accuracy_high_variance * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widzimy przy użyciu tylko 14 cech, zamiast 7070, nadal uzyskujemy wyniki na dobrym poziomie.\n",
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorytm rekursywnej eliminnacji cech\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importujemy potrzebne biblioteki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obliczamy próg `m`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_instances = X_train_high_variance.shape[0]\n",
    "m = n_instances // 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Używając dwóch klasyfikatorów, Regresji Logistycznej oraz Lasów Losowych, przy pomocy RFE wyznaczammy najważniejsze cechy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_lr = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "rfe_lr = RFE(estimator=estimator_lr, n_features_to_select=m)\n",
    "X_train_selected_lr = rfe_lr.fit_transform(X_train_high_variance, y_train.ravel())\n",
    "X_test_selected_lr = rfe_lr.transform(X_test_high_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_rf = RandomForestClassifier(random_state=42)\n",
    "rfe_rf = RFE(estimator=estimator_rf, n_features_to_select=m)\n",
    "X_train_selected_rf = rfe_rf.fit_transform(X_train_high_variance, y_train.ravel())\n",
    "X_test_selected_rf = rfe_rf.transform(X_test_high_variance)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sprawdzenie dokładności oraz AUC dla powyższych klasyfikatorów z wykorzystaniem 4-krotnej walidacji krzyżowej oraz przetransformowanych danych"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importujemy potrzebne biblioteki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-krotna walidacja krzyżowa z wyliczaniem dokładności i AUC dla dwóch klasyfikatorów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 4\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "mean_accuracy_lr = np.mean(cross_val_score(lr, X_transformed, y.ravel(), cv=cv, scoring='accuracy'))\n",
    "mean_accuracy_rf = np.mean(cross_val_score(rf, X_transformed, y.ravel(), cv=cv, scoring='accuracy'))\n",
    "\n",
    "mean_auc_lr = np.mean(cross_val_score(lr, X_transformed, y.ravel(), cv=cv, scoring='roc_auc'))\n",
    "mean_auc_rf = np.mean(cross_val_score(rf, X_transformed, y.ravel(), cv=cv, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Średnia dokładność dla regresji logistycznej: 93.06\n",
      "Średnia dokładność dla lasów losowych: 93.06\n",
      "Średnia metryka AUC dla regresji logistycznej: 98.29\n",
      "Średnia metryka AUC dla lasów losowych: 99.31\n"
     ]
    }
   ],
   "source": [
    "print(\"Średnia dokładność dla regresji logistycznej: {:.2f}\".format(mean_accuracy_lr * 100))\n",
    "print(\"Średnia dokładność dla lasów losowych: {:.2f}\".format(mean_accuracy_rf * 100))\n",
    "\n",
    "print(\"Średnia metryka AUC dla regresji logistycznej: {:.2f}\".format(mean_auc_lr * 100))\n",
    "print(\"Średnia metryka AUC dla lasów losowych: {:.2f}\".format(mean_auc_rf * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla lasów losowych uzyskaliśmy wyższy wynik AUC, niż dla regresji logistycznej. Dokładność obu klasyfikatorów jest bardzo zbliżona"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wbudowane metody selekcji cech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_l1 = LogisticRegression(solver='saga', penalty='l1', C=0.1, max_iter=1000) # regresja logistyczna z regularyzacją L1\n",
    "selector_l1 = SelectFromModel(estimator_l1)  # selektor używający metody regularyzacji L1\n",
    "X_train_l1 = selector_l1.fit_transform(X_train_high_variance, y_train.ravel())\n",
    "X_test_l1 = selector_l1.transform(X_test_high_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_rf = RandomForestClassifier(random_state=42) # estymator lasów losowych\n",
    "selector_rf = SelectFromModel(estimator_rf)  # selektor używający metody opartej na ważności cech dla lasów losowych\n",
    "X_train_rf = selector_rf.fit_transform(X_train_high_variance, y_train.ravel())\n",
    "X_test_rf = selector_rf.transform(X_test_high_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_rf = RandomForestClassifier(random_state=42) # estymator lasów losowych\n",
    "selector_rf = SelectFromModel(estimator_rf)  # selektor używający metody opartej na ważności cech dla lasów losowych\n",
    "X_train_rf = selector_rf.fit_transform(X_train_high_variance, y_train.ravel())\n",
    "X_test_rf = selector_rf.transform(X_test_high_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oryginalna regresja logistyczna\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "lr.fit(X_train_high_variance, y_train.ravel())\n",
    "y_pred_lr = lr.predict(X_test_high_variance)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "# Oryginalne lasy losowe\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train_high_variance, y_train.ravel())\n",
    "y_pred_rf = rf.predict(X_test_high_variance)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "# Regularyzacja L1 dla regresji logistycznej\n",
    "lr_l1 = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "lr_l1.fit(X_train_l1, y_train.ravel())\n",
    "y_pred_l1 = lr_l1.predict(X_test_l1)\n",
    "accuracy_l1 = accuracy_score(y_test, y_pred_l1)\n",
    "\n",
    "# Metoda oparta na ważności cech dla lasów losowych\n",
    "rf_selected = RandomForestClassifier(random_state=42)\n",
    "rf_selected.fit(X_train_rf, y_train.ravel())\n",
    "y_pred_rf_selected = rf_selected.predict(X_test_rf)\n",
    "accuracy_rf_selected = accuracy_score(y_test, y_pred_rf_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność regresji logistycznej: 95.45\n",
      "Dokładność lasów losowych: 95.45\n",
      "Dokładność regresji logistycznej z regularyzacją L1: 90.91\n",
      "Dokładność lasów losowych z metodą ważności cech: 86.36\n"
     ]
    }
   ],
   "source": [
    "print(\"Dokładność regresji logistycznej: {:.2f}\".format(accuracy_lr * 100))\n",
    "print(\"Dokładność lasów losowych: {:.2f}\".format(accuracy_rf * 100))\n",
    "print(\"Dokładność regresji logistycznej z regularyzacją L1: {:.2f}\".format(accuracy_l1 * 100))\n",
    "print(\"Dokładność lasów losowych z metodą ważności cech: {:.2f}\".format(accuracy_rf_selected * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 1. Wczytaj zbiór danych\n",
    "data = scipy.io.loadmat('data/leukemia.mat')\n",
    "X = data['X']\n",
    "Y = np.ravel(data['Y'])\n",
    "\n",
    "# 2. Usuń cechy o niskiej wariancji\n",
    "var_thresh = VarianceThreshold(threshold=1.0)\n",
    "X_high_variance = var_thresh.fit_transform(X)\n",
    "\n",
    "# 3. Wybierz `m` najlepszych cech\n",
    "m = X_high_variance.shape[0] // 3\n",
    "estimators = [LogisticRegression(solver='liblinear'), RandomForestClassifier()]\n",
    "\n",
    "rfe_models = {}\n",
    "for est in estimators:\n",
    "    rfe = RFE(estimator=est, n_features_to_select=m)\n",
    "    X_selected = rfe.fit_transform(X_high_variance, Y)\n",
    "    rfe_models[type(est).__name__] = {'estimator': est, 'X_selected': X_selected}\n",
    "\n",
    "# 4. Zbadaj wpływ metryk na dokładność klasyfikacji\n",
    "nr_splits = 6\n",
    "scores = {}\n",
    "for est_name, model_data in rfe_models.items():\n",
    "    est = model_data['estimator']\n",
    "    X_sel = model_data['X_selected']\n",
    "    acc_scores = cross_val_score(est, X_sel, Y, cv=nr_splits, scoring='accuracy')\n",
    "    auc_scores = cross_val_score(est, X_sel, Y, cv=nr_splits, scoring='roc_auc')\n",
    "    scores[est_name] = {'accuracy': acc_scores, 'auc': auc_scores}\n",
    "    \n",
    "# 5. Porównaj skuteczność z wbudowanymi metodami selekcji cech\n",
    "# (a) Regularyzacja L1 dla regresji logistycznej\n",
    "est_l1 = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "sfm_l1 = SelectFromModel(est_l1)\n",
    "X_sfm_l1 = sfm_l1.fit_transform(X, Y)\n",
    "\n",
    "# (b) Ważność cech dla lasów losowych\n",
    "est_rf = RandomForestClassifier()\n",
    "sfm_rf = SelectFromModel(est_rf)\n",
    "X_sfm_rf = sfm_rf.fit_transform(X, Y)\n",
    "\n",
    "sfm_models = {'LogisticRegression_L1': {'estimator': est_l1, 'X_selected': X_sfm_l1},\n",
    "              'RandomForest_FI': {'estimator': est_rf, 'X_selected': X_sfm_rf}}\n",
    "\n",
    "sfm_scores = {}\n",
    "for est_name, model_data in sfm_models.items():\n",
    "    est = model_data['estimator']\n",
    "    X_sel = model_data['X_selected']\n",
    "    acc_scores = cross_val_score(est, X_sel, Y, cv=nr_splits, scoring='accuracy')\n",
    "    auc_scores = cross_val_score(est, X_sel, Y, cv=nr_splits, scoring='roc_auc')\n",
    "    sfm_scores[est_name] = {'accuracy': acc_scores, 'auc': auc_scores}\n",
    "\n",
    "# Porównanie skuteczności - dokładność\n",
    "print(\"Scores for RFE models:\")\n",
    "for model_name, score_data in scores.items():\n",
    "    print(f\"{model_name}: accuracy={np.mean(score_data['accuracy']):.2f}, auc={np.mean(score_data['auc']):.2f}\")\n",
    "\n",
    "print(\"\\nScores for SFM models:\")\n",
    "for model_name, score_data in sfm_scores.items():\n",
    "    print(f\"{model_name}: accuracy={np.mean(score_data['accuracy']):.2f}, auc={np.mean(score_data['auc']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
